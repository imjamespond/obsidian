:label:`sec_kaggle_house`

ä¹‹å‰å‡ èŠ‚æˆ‘ä»¬å­¦ä¹ äº†ä¸€äº›è®­ç»ƒæ·±åº¦ç½‘ç»œçš„åŸºæœ¬å·¥å…·å’Œç½‘ç»œæ­£åˆ™åŒ–çš„æŠ€æœ¯ï¼ˆå¦‚æƒé‡è¡°å‡ã€æš‚é€€æ³•ç­‰ï¼‰ã€‚
æœ¬èŠ‚æˆ‘ä»¬å°†é€šè¿‡Kaggleæ¯”èµ›ï¼Œå°†æ‰€å­¦çŸ¥è¯†ä»˜è¯¸å®è·µã€‚
Kaggleçš„æˆ¿ä»·é¢„æµ‹æ¯”èµ›æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚
æ­¤æ•°æ®é›†ç”±Bart de Cockäº2011å¹´æ”¶é›† :cite:`De-Cock.2011`ï¼Œ
æ¶µç›–äº†2006-2010å¹´æœŸé—´äºšåˆ©æ¡‘é‚£å·åŸƒå§†æ–¯å¸‚çš„æˆ¿ä»·ã€‚
è¿™ä¸ªæ•°æ®é›†æ˜¯ç›¸å½“é€šç”¨çš„ï¼Œä¸ä¼šéœ€è¦ä½¿ç”¨å¤æ‚æ¨¡å‹æ¶æ„ã€‚
å®ƒæ¯”å“ˆé‡Œæ£®å’Œé²å®¾è²å°”å¾·çš„[æ³¢å£«é¡¿æˆ¿ä»·](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names)
æ•°æ®é›†è¦å¤§å¾—å¤šï¼Œä¹Ÿæœ‰æ›´å¤šçš„ç‰¹å¾ã€‚

æœ¬èŠ‚æˆ‘ä»¬å°†è¯¦ç»†ä»‹ç»æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®¾è®¡å’Œè¶…å‚æ•°é€‰æ‹©ã€‚
é€šè¿‡äº²èº«å®è·µï¼Œä½ å°†è·å¾—ä¸€æ‰‹ç»éªŒï¼Œè¿™äº›ç»éªŒå°†æœ‰ç›Šæ•°æ®ç§‘å­¦å®¶çš„èŒä¸šæˆé•¿ã€‚

## ä¸‹è½½å’Œç¼“å­˜æ•°æ®é›†

åœ¨æ•´æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬å°†ä¸‹è½½ä¸åŒçš„æ•°æ®é›†ï¼Œå¹¶è®­ç»ƒå’Œæµ‹è¯•æ¨¡å‹ã€‚
è¿™é‡Œæˆ‘ä»¬(**å®ç°å‡ ä¸ªå‡½æ•°æ¥æ–¹ä¾¿ä¸‹è½½æ•°æ®**)ã€‚
é¦–å…ˆï¼Œæˆ‘ä»¬å»ºç«‹å­—å…¸`DATA_HUB`ï¼Œ
å®ƒå¯ä»¥å°†æ•°æ®é›†åç§°çš„å­—ç¬¦ä¸²æ˜ å°„åˆ°æ•°æ®é›†ç›¸å…³çš„äºŒå…ƒç»„ä¸Šï¼Œ
è¿™ä¸ªäºŒå…ƒç»„åŒ…å«æ•°æ®é›†çš„urlå’ŒéªŒè¯æ–‡ä»¶å®Œæ•´æ€§çš„sha-1å¯†é’¥ã€‚
æ‰€æœ‰ç±»ä¼¼çš„æ•°æ®é›†éƒ½æ‰˜ç®¡åœ¨åœ°å€ä¸º`DATA_URL`çš„ç«™ç‚¹ä¸Šã€‚

ä¸‹é¢çš„`download`å‡½æ•°ç”¨æ¥ä¸‹è½½æ•°æ®é›†ï¼Œ
å°†æ•°æ®é›†ç¼“å­˜åœ¨æœ¬åœ°ç›®å½•ï¼ˆé»˜è®¤æƒ…å†µä¸‹ä¸º`../data`ï¼‰ä¸­ï¼Œ
å¹¶è¿”å›ä¸‹è½½æ–‡ä»¶çš„åç§°ã€‚
å¦‚æœç¼“å­˜ç›®å½•ä¸­å·²ç»å­˜åœ¨æ­¤æ•°æ®é›†æ–‡ä»¶ï¼Œå¹¶ä¸”å…¶sha-1ä¸å­˜å‚¨åœ¨`DATA_HUB`ä¸­çš„ç›¸åŒ¹é…ï¼Œ
æˆ‘ä»¬å°†ä½¿ç”¨ç¼“å­˜çš„æ–‡ä»¶ï¼Œä»¥é¿å…é‡å¤çš„ä¸‹è½½ã€‚

æˆ‘ä»¬è¿˜éœ€å®ç°ä¸¤ä¸ªå®ç”¨å‡½æ•°ï¼š
ä¸€ä¸ªå°†ä¸‹è½½å¹¶è§£å‹ç¼©ä¸€ä¸ªzipæˆ–taræ–‡ä»¶ï¼Œ
å¦ä¸€ä¸ªæ˜¯å°†æœ¬ä¹¦ä¸­ä½¿ç”¨çš„æ‰€æœ‰æ•°æ®é›†ä»`DATA_HUB`ä¸‹è½½åˆ°ç¼“å­˜ç›®å½•ä¸­ã€‚


```python
import hashlib
import os
import tarfile
import zipfile
import requests

#@save
DATA_HUB = dict()
DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'

def download(name, cache_dir=os.path.join('..', 'data')):  #@save
    """ä¸‹è½½ä¸€ä¸ªDATA_HUBä¸­çš„æ–‡ä»¶ï¼Œè¿”å›æœ¬åœ°æ–‡ä»¶å"""
    assert name in DATA_HUB, f"{name} ä¸å­˜åœ¨äº {DATA_HUB}"
    url, sha1_hash = DATA_HUB[name]
    os.makedirs(cache_dir, exist_ok=True)
    fname = os.path.join(cache_dir, url.split('/')[-1])
    if os.path.exists(fname):
        sha1 = hashlib.sha1()
        with open(fname, 'rb') as f:
            while True:
                data = f.read(1048576)
                if not data:
                    break
                sha1.update(data)
        if sha1.hexdigest() == sha1_hash:
            return fname  # å‘½ä¸­ç¼“å­˜
    print(f'æ­£åœ¨ä»{url}ä¸‹è½½{fname}...')
    r = requests.get(url, stream=True, verify=True)
    with open(fname, 'wb') as f:
        f.write(r.content)
    return fname

def download_extract(name, folder=None):  #@save
    """ä¸‹è½½å¹¶è§£å‹zip/taræ–‡ä»¶"""
    fname = download(name)
    base_dir = os.path.dirname(fname)
    data_dir, ext = os.path.splitext(fname)
    if ext == '.zip':
        fp = zipfile.ZipFile(fname, 'r')
    elif ext in ('.tar', '.gz'):
        fp = tarfile.open(fname, 'r')
    else:
        assert False, 'åªæœ‰zip/taræ–‡ä»¶å¯ä»¥è¢«è§£å‹ç¼©'
    fp.extractall(base_dir)
    return os.path.join(base_dir, folder) if folder else data_dir

def download_all():  #@save
    """ä¸‹è½½DATA_HUBä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
    for name in DATA_HUB:
        download(name)
```

## Kaggle

[Kaggle](https://www.kaggle.com)æ˜¯ä¸€ä¸ªå½“ä»Šæµè¡Œä¸¾åŠæœºå™¨å­¦ä¹ æ¯”èµ›çš„å¹³å°ï¼Œ
æ¯åœºæ¯”èµ›éƒ½ä»¥è‡³å°‘ä¸€ä¸ªæ•°æ®é›†ä¸ºä¸­å¿ƒã€‚
è®¸å¤šæ¯”èµ›æœ‰èµåŠ©æ–¹ï¼Œä»–ä»¬ä¸ºè·èƒœçš„è§£å†³æ–¹æ¡ˆæä¾›å¥–é‡‘ã€‚
è¯¥å¹³å°å¸®åŠ©ç”¨æˆ·é€šè¿‡è®ºå›å’Œå…±äº«ä»£ç è¿›è¡Œäº’åŠ¨ï¼Œä¿ƒè¿›åä½œå’Œç«äº‰ã€‚
è™½ç„¶æ’è¡Œæ¦œçš„è¿½é€å¾€å¾€ä»¤äººå¤±å»ç†æ™ºï¼š
æœ‰äº›ç ”ç©¶äººå‘˜çŸ­è§†åœ°ä¸“æ³¨äºé¢„å¤„ç†æ­¥éª¤ï¼Œè€Œä¸æ˜¯è€ƒè™‘åŸºç¡€æ€§é—®é¢˜ã€‚
ä½†ä¸€ä¸ªå®¢è§‚çš„å¹³å°æœ‰å·¨å¤§çš„ä»·å€¼ï¼šè¯¥å¹³å°ä¿ƒè¿›äº†ç«äº‰æ–¹æ³•ä¹‹é—´çš„ç›´æ¥å®šé‡æ¯”è¾ƒï¼Œä»¥åŠä»£ç å…±äº«ã€‚
è¿™ä¾¿äºæ¯ä¸ªäººéƒ½å¯ä»¥å­¦ä¹ å“ªäº›æ–¹æ³•èµ·ä½œç”¨ï¼Œå“ªäº›æ²¡æœ‰èµ·ä½œç”¨ã€‚
å¦‚æœæˆ‘ä»¬æƒ³å‚åŠ Kaggleæ¯”èµ›ï¼Œé¦–å…ˆéœ€è¦æ³¨å†Œä¸€ä¸ªè´¦æˆ·ï¼ˆè§ :numref:`fig_kaggle`ï¼‰ã€‚

![[Pasted image 20240304132928.png|500]]

:label:`fig_kaggle`

åœ¨æˆ¿ä»·é¢„æµ‹æ¯”èµ›é¡µé¢ï¼ˆå¦‚ :numref:`fig_house_pricing` æ‰€ç¤ºï¼‰çš„"Data"é€‰é¡¹å¡ä¸‹å¯ä»¥æ‰¾åˆ°æ•°æ®é›†ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„ç½‘å€æäº¤é¢„æµ‹ï¼Œå¹¶æŸ¥çœ‹æ’åï¼š

>https://www.kaggle.com/c/house-prices-advanced-regression-techniques

![[Pasted image 20240304132956.png|500]]
:label:`fig_house_pricing`

## è®¿é—®å’Œè¯»å–æ•°æ®é›†

æ³¨æ„ï¼Œç«èµ›æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚
æ¯æ¡è®°å½•éƒ½åŒ…æ‹¬æˆ¿å±‹çš„å±æ€§å€¼å’Œå±æ€§ï¼Œå¦‚è¡—é“ç±»å‹ã€æ–½å·¥å¹´ä»½ã€å±‹é¡¶ç±»å‹ã€åœ°ä¸‹å®¤çŠ¶å†µç­‰ã€‚
è¿™äº›ç‰¹å¾ç”±å„ç§æ•°æ®ç±»å‹ç»„æˆã€‚
ä¾‹å¦‚ï¼Œå»ºç­‘å¹´ä»½ç”±æ•´æ•°è¡¨ç¤ºï¼Œå±‹é¡¶ç±»å‹ç”±ç¦»æ•£ç±»åˆ«è¡¨ç¤ºï¼Œå…¶ä»–ç‰¹å¾ç”±æµ®ç‚¹æ•°è¡¨ç¤ºã€‚
è¿™å°±æ˜¯ç°å®è®©äº‹æƒ…å˜å¾—å¤æ‚çš„åœ°æ–¹ï¼šä¾‹å¦‚ï¼Œä¸€äº›æ•°æ®å®Œå…¨ä¸¢å¤±äº†ï¼Œç¼ºå¤±å€¼è¢«ç®€å•åœ°æ ‡è®°ä¸ºâ€œNAâ€ã€‚
æ¯å¥—æˆ¿å­çš„ä»·æ ¼åªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­ï¼ˆæ¯•ç«Ÿè¿™æ˜¯ä¸€åœºæ¯”èµ›ï¼‰ã€‚
æˆ‘ä»¬å°†å¸Œæœ›åˆ’åˆ†è®­ç»ƒé›†ä»¥åˆ›å»ºéªŒè¯é›†ï¼Œä½†æ˜¯åœ¨å°†é¢„æµ‹ç»“æœä¸Šä¼ åˆ°Kaggleä¹‹åï¼Œ
æˆ‘ä»¬åªèƒ½åœ¨å®˜æ–¹æµ‹è¯•é›†ä¸­è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚
åœ¨ :numref:`fig_house_pricing` ä¸­ï¼Œ"Data"é€‰é¡¹å¡æœ‰ä¸‹è½½æ•°æ®çš„é“¾æ¥ã€‚

å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬å°†\[**ä½¿ç”¨`pandas`è¯»å…¥å¹¶å¤„ç†æ•°æ®**]ï¼Œ
è¿™æ˜¯æˆ‘ä»¬åœ¨ :numref:`sec_pandas`ä¸­å¼•å…¥çš„ã€‚
å› æ­¤ï¼Œåœ¨ç»§ç»­æ“ä½œä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿å·²å®‰è£…`pandas`ã€‚
å¹¸è¿çš„æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æ­£åœ¨ç”¨Jupyteré˜…è¯»è¯¥ä¹¦ï¼Œå¯ä»¥åœ¨ä¸ç¦»å¼€ç¬”è®°æœ¬çš„æƒ…å†µä¸‹å®‰è£…`pandas`ã€‚

ä¸ºæ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„è„šæœ¬ä¸‹è½½å¹¶ç¼“å­˜Kaggleæˆ¿å±‹æ•°æ®é›†ã€‚

æˆ‘ä»¬ä½¿ç”¨`pandas`åˆ†åˆ«åŠ è½½åŒ…å«è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„ä¸¤ä¸ªCSVæ–‡ä»¶ã€‚

è®­ç»ƒæ•°æ®é›†åŒ…æ‹¬1460ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬80ä¸ªç‰¹å¾å’Œ1ä¸ªæ ‡ç­¾ï¼Œ
è€Œæµ‹è¯•æ•°æ®é›†åŒ…å«1459ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬80ä¸ªç‰¹å¾ã€‚


```python
# å¦‚æœæ²¡æœ‰å®‰è£…pandasï¼Œè¯·å–æ¶ˆä¸‹ä¸€è¡Œçš„æ³¨é‡Š
# !pip install pandas

import numpy as np
import pandas as pd
import torch
from torch import nn
from d2l import torch as d2l


DATA_HUB['kaggle_house_train'] = (  #@save
    DATA_URL + 'kaggle_house_pred_train.csv',
    '585e9cc93e70b39160e7921475f9bcd7d31219ce')

DATA_HUB['kaggle_house_test'] = (  #@save
    DATA_URL + 'kaggle_house_pred_test.csv',
    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')

train_data = pd.read_csv(download('kaggle_house_train'))
test_data = pd.read_csv(download('kaggle_house_test'))

"""
æ­£åœ¨ä»http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csvä¸‹è½½../data/kaggle_house_pred_train.csv...
æ­£åœ¨ä»http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csvä¸‹è½½../data/kaggle_house_pred_test.csv...
"""

print(train_data.shape)
print(test_data.shape)
"""
(1460, 81)
(1459, 80)
"""

# è®©æˆ‘ä»¬çœ‹çœ‹[å‰å››ä¸ªå’Œæœ€åä¸¤ä¸ªç‰¹å¾ï¼Œä»¥åŠç›¸åº”æ ‡ç­¾]ï¼ˆæˆ¿ä»·ï¼‰ã€‚
print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])
"""
   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice
0   1          60       RL         65.0       WD        Normal     208500
1   2          20       RL         80.0       WD        Normal     181500
2   3          60       RL         68.0       WD        Normal     223500
3   4          70       RL         60.0       WD       Abnorml     140000
"""

# æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œ(**åœ¨æ¯ä¸ªæ ·æœ¬ä¸­ï¼Œç¬¬ä¸€ä¸ªç‰¹å¾æ˜¯IDï¼Œ**) è¿™æœ‰åŠ©äºæ¨¡å‹è¯†åˆ«æ¯ä¸ªè®­ç»ƒæ ·æœ¬ã€‚ è™½ç„¶è¿™å¾ˆæ–¹ä¾¿ï¼Œä½†å®ƒä¸æºå¸¦ä»»ä½•ç”¨äºé¢„æµ‹çš„ä¿¡æ¯ã€‚ å› æ­¤ï¼Œåœ¨å°†æ•°æ®æä¾›ç»™æ¨¡å‹ä¹‹å‰ï¼Œ(**æˆ‘ä»¬å°†å…¶ä»æ•°æ®é›†ä¸­åˆ é™¤**)ã€‚
all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))
```

## æ•°æ®é¢„å¤„ç†

å¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬æœ‰å„ç§å„æ ·çš„æ•°æ®ç±»å‹ã€‚
åœ¨å¼€å§‹å»ºæ¨¡ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚
é¦–å…ˆï¼Œæˆ‘ä»¬\[**å°†æ‰€æœ‰ç¼ºå¤±çš„å€¼æ›¿æ¢ä¸ºç›¸åº”ç‰¹å¾çš„å¹³å‡å€¼ã€‚**]ç„¶åï¼Œä¸ºäº†å°†æ‰€æœ‰ç‰¹å¾æ”¾åœ¨ä¸€ä¸ªå…±åŒçš„å°ºåº¦ä¸Šï¼Œ
æˆ‘ä»¬(**é€šè¿‡å°†ç‰¹å¾é‡æ–°ç¼©æ”¾åˆ°é›¶å‡å€¼å’Œå•ä½æ–¹å·®æ¥æ ‡å‡†åŒ–æ•°æ®**)ï¼š

$$x \leftarrow \frac{x - \mu}{\sigma},$$

å…¶ä¸­$\mu$å’Œ$\sigma$åˆ†åˆ«è¡¨ç¤ºå‡å€¼å’Œæ ‡å‡†å·®ã€‚
ç°åœ¨ï¼Œè¿™äº›ç‰¹å¾å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼Œå³ $E[\frac{x-\mu}{\sigma}] = \frac{\mu - \mu}{\sigma} = 0$å’Œ$E[(x-\mu)^2] = (\sigma^2 + \mu^2) - 2\mu^2+\mu^2 = \sigma^2$ã€‚
ç›´è§‚åœ°è¯´ï¼Œæˆ‘ä»¬æ ‡å‡†åŒ–æ•°æ®æœ‰ä¸¤ä¸ªåŸå› ï¼š
é¦–å…ˆï¼Œå®ƒæ–¹ä¾¿ä¼˜åŒ–ã€‚
å…¶æ¬¡ï¼Œå› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“å“ªäº›ç‰¹å¾æ˜¯ç›¸å…³çš„ï¼Œ
æ‰€ä»¥æˆ‘ä»¬ä¸æƒ³è®©æƒ©ç½šåˆ†é…ç»™ä¸€ä¸ªç‰¹å¾çš„ç³»æ•°æ¯”åˆ†é…ç»™å…¶ä»–ä»»ä½•ç‰¹å¾çš„ç³»æ•°æ›´å¤§ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬\[**å¤„ç†ç¦»æ•£å€¼ã€‚**]
è¿™åŒ…æ‹¬è¯¸å¦‚â€œMSZoningâ€ä¹‹ç±»çš„ç‰¹å¾ã€‚
(**æˆ‘ä»¬ç”¨ç‹¬çƒ­ç¼–ç æ›¿æ¢å®ƒä»¬**)ï¼Œ
æ–¹æ³•ä¸å‰é¢å°†å¤šç±»åˆ«æ ‡ç­¾è½¬æ¢ä¸ºå‘é‡çš„æ–¹å¼ç›¸åŒ
ï¼ˆè¯·å‚è§ :numref:`subsec_classification-problem`ï¼‰ã€‚
ä¾‹å¦‚ï¼Œâ€œMSZoningâ€åŒ…å«å€¼â€œRLâ€å’Œâ€œRmâ€ã€‚
æˆ‘ä»¬å°†åˆ›å»ºä¸¤ä¸ªæ–°çš„æŒ‡ç¤ºå™¨ç‰¹å¾â€œMSZoning_RLâ€å’Œâ€œMSZoning_RMâ€ï¼Œå…¶å€¼ä¸º0æˆ–1ã€‚
æ ¹æ®ç‹¬çƒ­ç¼–ç ï¼Œå¦‚æœâ€œMSZoningâ€çš„åŸå§‹å€¼ä¸ºâ€œRLâ€ï¼Œ
åˆ™ï¼šâ€œMSZoning_RLâ€ä¸º1ï¼Œâ€œMSZoning_RMâ€ä¸º0ã€‚
`pandas`è½¯ä»¶åŒ…ä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬å®ç°è¿™ä¸€ç‚¹ã€‚

```python
# è‹¥æ— æ³•è·å¾—æµ‹è¯•æ•°æ®ï¼Œåˆ™å¯æ ¹æ®è®­ç»ƒæ•°æ®è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index
all_features[numeric_features] = all_features[numeric_features].apply(
    lambda x: (x - x.mean()) / (x.std()))
# åœ¨æ ‡å‡†åŒ–æ•°æ®ä¹‹åï¼Œæ‰€æœ‰å‡å€¼æ¶ˆå¤±ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†ç¼ºå¤±å€¼è®¾ç½®ä¸º0
all_features[numeric_features] = all_features[numeric_features].fillna(0)

# â€œDummy_na=Trueâ€å°†â€œnaâ€ï¼ˆç¼ºå¤±å€¼ï¼‰è§†ä¸ºæœ‰æ•ˆçš„ç‰¹å¾å€¼ï¼Œå¹¶ä¸ºå…¶åˆ›å»ºæŒ‡ç¤ºç¬¦ç‰¹å¾
all_features = pd.get_dummies(all_features, dummy_na=True)
all_features.shape
'''
(2919, 331)
'''

# å¯ä»¥çœ‹åˆ°æ­¤è½¬æ¢ä¼šå°†ç‰¹å¾çš„æ€»æ•°é‡ä»79ä¸ªå¢åŠ åˆ°331ä¸ªã€‚ æœ€åï¼Œé€šè¿‡`values`å±æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ [**ä»`pandas`æ ¼å¼ä¸­æå–NumPyæ ¼å¼ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡è¡¨ç¤º**]ç”¨äºè®­ç»ƒã€‚

n_train = train_data.shape[0]
train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)
test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)
train_labels = torch.tensor(
    train_data.SalePrice.values.reshape(-1, 1), dtype=torch.float32)
```

## [**è®­ç»ƒ**]

é¦–å…ˆï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªå¸¦æœ‰æŸå¤±å¹³æ–¹çš„çº¿æ€§æ¨¡å‹ã€‚
æ˜¾ç„¶çº¿æ€§æ¨¡å‹å¾ˆéš¾è®©æˆ‘ä»¬åœ¨ç«èµ›ä¸­è·èƒœï¼Œä½†çº¿æ€§æ¨¡å‹æä¾›äº†ä¸€ç§å¥å…¨æ€§æ£€æŸ¥ï¼Œ
ä»¥æŸ¥çœ‹æ•°æ®ä¸­æ˜¯å¦å­˜åœ¨æœ‰æ„ä¹‰çš„ä¿¡æ¯ã€‚
å¦‚æœæˆ‘ä»¬åœ¨è¿™é‡Œä¸èƒ½åšå¾—æ¯”éšæœºçŒœæµ‹æ›´å¥½ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¾ˆå¯èƒ½å­˜åœ¨æ•°æ®å¤„ç†é”™è¯¯ã€‚
å¦‚æœä¸€åˆ‡é¡ºåˆ©ï¼Œçº¿æ€§æ¨¡å‹å°†ä½œä¸º*åŸºçº¿*ï¼ˆbaselineï¼‰æ¨¡å‹ï¼Œ
è®©æˆ‘ä»¬ç›´è§‚åœ°çŸ¥é“æœ€å¥½çš„æ¨¡å‹æœ‰è¶…å‡ºç®€å•çš„æ¨¡å‹å¤šå°‘ã€‚

```python
loss = nn.MSELoss()
in_features = train_features.shape[1]

def get_net():
    net = nn.Sequential(nn.Linear(in_features,1))
    return net
```

æˆ¿ä»·å°±åƒè‚¡ç¥¨ä»·æ ¼ä¸€æ ·ï¼Œæˆ‘ä»¬å…³å¿ƒçš„æ˜¯ç›¸å¯¹æ•°é‡ï¼Œè€Œä¸æ˜¯ç»å¯¹æ•°é‡ã€‚
å› æ­¤ï¼Œ\[**æˆ‘ä»¬æ›´å…³å¿ƒç›¸å¯¹è¯¯å·®$\frac{y - \hat{y}}{y}$ï¼Œ**]
è€Œä¸æ˜¯ç»å¯¹è¯¯å·®$y - \hat{y}$ã€‚
ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬åœ¨ä¿„äº¥ä¿„å·å†œæ‘åœ°åŒºä¼°è®¡ä¸€æ ‹æˆ¿å­çš„ä»·æ ¼æ—¶ï¼Œ
å‡è®¾æˆ‘ä»¬çš„é¢„æµ‹åå·®äº†10ä¸‡ç¾å…ƒï¼Œ
ç„¶è€Œé‚£é‡Œä¸€æ ‹å…¸å‹çš„æˆ¿å­çš„ä»·å€¼æ˜¯12.5ä¸‡ç¾å…ƒï¼Œ
é‚£ä¹ˆæ¨¡å‹å¯èƒ½åšå¾—å¾ˆç³Ÿç³•ã€‚
å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæˆ‘ä»¬åœ¨åŠ å·è±ªå®…åŒºçš„é¢„æµ‹å‡ºç°åŒæ ·çš„10ä¸‡ç¾å…ƒçš„åå·®ï¼Œ
ï¼ˆåœ¨é‚£é‡Œï¼Œæˆ¿ä»·ä¸­ä½æ•°è¶…è¿‡400ä¸‡ç¾å…ƒï¼‰
è¿™å¯èƒ½æ˜¯ä¸€ä¸ªä¸é”™çš„é¢„æµ‹ã€‚

(**è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯ç”¨ä»·æ ¼é¢„æµ‹çš„å¯¹æ•°æ¥è¡¡é‡å·®å¼‚**)ã€‚
äº‹å®ä¸Šï¼Œè¿™ä¹Ÿæ˜¯æ¯”èµ›ä¸­å®˜æ–¹ç”¨æ¥è¯„ä»·æäº¤è´¨é‡çš„è¯¯å·®æŒ‡æ ‡ã€‚
å³å°†$\delta$ for $|\log y - \log \hat{y}| \leq \delta$
è½¬æ¢ä¸º$e^{-\delta} \leq \frac{\hat{y}}{y} \leq e^\delta$ã€‚
è¿™ä½¿å¾—é¢„æµ‹ä»·æ ¼çš„å¯¹æ•°ä¸çœŸå®æ ‡ç­¾ä»·æ ¼çš„å¯¹æ•°ä¹‹é—´å‡ºç°ä»¥ä¸‹å‡æ–¹æ ¹è¯¯å·®ï¼š

$$\sqrt{\frac{1}{n}\sum_{i=1}^n\left(\log y_i -\log \hat{y}_i\right)^2}.$$

```python
def log_rmse(net, features, labels):
    # ä¸ºäº†åœ¨å–å¯¹æ•°æ—¶è¿›ä¸€æ­¥ç¨³å®šè¯¥å€¼ï¼Œå°†å°äº1çš„å€¼è®¾ç½®ä¸º1
    clipped_preds = torch.clamp(net(features), 1, float('inf'))
    rmse = torch.sqrt(loss(torch.log(clipped_preds),
                           torch.log(labels)))
    return rmse.item()

# ä¸å‰é¢çš„éƒ¨åˆ†ä¸åŒï¼Œ[**æˆ‘ä»¬çš„è®­ç»ƒå‡½æ•°å°†å€ŸåŠ©Adamä¼˜åŒ–å™¨**] ï¼ˆæˆ‘ä»¬å°†åœ¨åé¢ç« èŠ‚æ›´è¯¦ç»†åœ°æè¿°å®ƒï¼‰ã€‚ Adamä¼˜åŒ–å™¨çš„ä¸»è¦å¸å¼•åŠ›åœ¨äºå®ƒå¯¹åˆå§‹å­¦ä¹ ç‡ä¸é‚£ä¹ˆæ•æ„Ÿã€‚

def train(net, train_features, train_labels, test_features, test_labels,
          num_epochs, learning_rate, weight_decay, batch_size):
    train_ls, test_ls = [], []
    train_iter = d2l.load_array((train_features, train_labels), batch_size)
    # è¿™é‡Œä½¿ç”¨çš„æ˜¯Adamä¼˜åŒ–ç®—æ³•
    optimizer = torch.optim.Adam(net.parameters(),
                                 lr = learning_rate,
                                 weight_decay = weight_decay)
    for epoch in range(num_epochs):
        for X, y in train_iter:
            optimizer.zero_grad()
            l = loss(net(X), y)
            l.backward()
            optimizer.step()
        train_ls.append(log_rmse(net, train_features, train_labels))
        if test_labels is not None:
            test_ls.append(log_rmse(net, test_features, test_labels))
    return train_ls, test_ls
```

## $K$æŠ˜äº¤å‰éªŒè¯

æœ¬ä¹¦åœ¨è®¨è®ºæ¨¡å‹é€‰æ‹©çš„éƒ¨åˆ†ï¼ˆ :numref:`sec_model_selection`ï¼‰
ä¸­ä»‹ç»äº†[**KæŠ˜äº¤å‰éªŒè¯**]ï¼Œ
å®ƒæœ‰åŠ©äºæ¨¡å‹é€‰æ‹©å’Œè¶…å‚æ•°è°ƒæ•´ã€‚
æˆ‘ä»¬é¦–å…ˆéœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œåœ¨$K$æŠ˜äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­è¿”å›ç¬¬$i$æŠ˜çš„æ•°æ®ã€‚
å…·ä½“åœ°è¯´ï¼Œå®ƒé€‰æ‹©ç¬¬$i$ä¸ªåˆ‡ç‰‡ä½œä¸ºéªŒè¯æ•°æ®ï¼Œå…¶ä½™éƒ¨åˆ†ä½œä¸ºè®­ç»ƒæ•°æ®ã€‚
æ³¨æ„ï¼Œè¿™å¹¶ä¸æ˜¯å¤„ç†æ•°æ®çš„æœ€æœ‰æ•ˆæ–¹æ³•ï¼Œå¦‚æœæˆ‘ä»¬çš„æ•°æ®é›†å¤§å¾—å¤šï¼Œä¼šæœ‰å…¶ä»–è§£å†³åŠæ³•ã€‚

```python
def get_k_fold_data(k, i, X, y):
    assert k > 1
    fold_size = X.shape[0] // k
    X_train, y_train = None, None
    for j in range(k):
        idx = slice(j * fold_size, (j + 1) * fold_size)
        X_part, y_part = X[idx, :], y[idx]
        if j == i:
            X_valid, y_valid = X_part, y_part
        elif X_train is None:
            X_train, y_train = X_part, y_part
        else:
            X_train = torch.cat([X_train, X_part], 0)
            y_train = torch.cat([y_train, y_part], 0)
    return X_train, y_train, X_valid, y_valid

# å½“æˆ‘ä»¬åœ¨ğ¾ï¿½æŠ˜äº¤å‰éªŒè¯ä¸­è®­ç»ƒğ¾ï¿½æ¬¡åï¼Œ[**è¿”å›è®­ç»ƒå’ŒéªŒè¯è¯¯å·®çš„å¹³å‡å€¼**]ã€‚

def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,
           batch_size):
    train_l_sum, valid_l_sum = 0, 0
    for i in range(k):
        data = get_k_fold_data(k, i, X_train, y_train)
        net = get_net()
        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,
                                   weight_decay, batch_size)
        train_l_sum += train_ls[-1]
        valid_l_sum += valid_ls[-1]
        if i == 0:
            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],
                     xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],
                     legend=['train', 'valid'], yscale='log')
        print(f'æŠ˜{i + 1}ï¼Œè®­ç»ƒlog rmse{float(train_ls[-1]):f}, '
              f'éªŒè¯log rmse{float(valid_ls[-1]):f}')
    return train_l_sum / k, valid_l_sum / k
```


## \[**æ¨¡å‹é€‰æ‹©**]

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸€ç»„æœªè°ƒä¼˜çš„è¶…å‚æ•°ï¼Œå¹¶å°†å…¶ç•™ç»™è¯»è€…æ¥æ”¹è¿›æ¨¡å‹ã€‚
æ‰¾åˆ°ä¸€ç»„è°ƒä¼˜çš„è¶…å‚æ•°å¯èƒ½éœ€è¦æ—¶é—´ï¼Œè¿™å–å†³äºä¸€ä¸ªäººä¼˜åŒ–äº†å¤šå°‘å˜é‡ã€‚
æœ‰äº†è¶³å¤Ÿå¤§çš„æ•°æ®é›†å’Œåˆç†è®¾ç½®çš„è¶…å‚æ•°ï¼Œ$K$æŠ˜äº¤å‰éªŒè¯å¾€å¾€å¯¹å¤šæ¬¡æµ‹è¯•å…·æœ‰ç›¸å½“çš„ç¨³å®šæ€§ã€‚
ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å°è¯•äº†ä¸åˆç†çš„è¶…å‚æ•°ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå‘ç°éªŒè¯æ•ˆæœä¸å†ä»£è¡¨çœŸæ­£çš„è¯¯å·®ã€‚

```python
k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64
train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,
                          weight_decay, batch_size)
print(f'{k}-æŠ˜éªŒè¯: å¹³å‡è®­ç»ƒlog rmse: {float(train_l):f}, '
      f'å¹³å‡éªŒè¯log rmse: {float(valid_l):f}')

'''
æŠ˜1ï¼Œè®­ç»ƒlog rmse0.169875, éªŒè¯log rmse0.157240
æŠ˜2ï¼Œè®­ç»ƒlog rmse0.162032, éªŒè¯log rmse0.189901
æŠ˜3ï¼Œè®­ç»ƒlog rmse0.163996, éªŒè¯log rmse0.168429
æŠ˜4ï¼Œè®­ç»ƒlog rmse0.167954, éªŒè¯log rmse0.154614
æŠ˜5ï¼Œè®­ç»ƒlog rmse0.162991, éªŒè¯log rmse0.182689
5-æŠ˜éªŒè¯: å¹³å‡è®­ç»ƒlog rmse: 0.165369, å¹³å‡éªŒè¯log rmse: 0.170575

<Figure size 350x250 with 1 Axes>
'''
```

è¯·æ³¨æ„ï¼Œæœ‰æ—¶ä¸€ç»„è¶…å‚æ•°çš„è®­ç»ƒè¯¯å·®å¯èƒ½éå¸¸ä½ï¼Œä½†$K$æŠ˜äº¤å‰éªŒè¯çš„è¯¯å·®è¦é«˜å¾—å¤šï¼Œ
è¿™è¡¨æ˜æ¨¡å‹è¿‡æ‹Ÿåˆäº†ã€‚
åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›ç›‘æ§è®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®è¿™ä¸¤ä¸ªæ•°å­—ã€‚
è¾ƒå°‘çš„è¿‡æ‹Ÿåˆå¯èƒ½è¡¨æ˜ç°æœ‰æ•°æ®å¯ä»¥æ”¯æ’‘ä¸€ä¸ªæ›´å¼ºå¤§çš„æ¨¡å‹ï¼Œ
è¾ƒå¤§çš„è¿‡æ‹Ÿåˆå¯èƒ½æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é€šè¿‡æ­£åˆ™åŒ–æŠ€æœ¯æ¥è·ç›Šã€‚

##  \[**æäº¤Kaggleé¢„æµ‹**]

æ—¢ç„¶æˆ‘ä»¬çŸ¥é“åº”è¯¥é€‰æ‹©ä»€ä¹ˆæ ·çš„è¶…å‚æ•°ï¼Œ
æˆ‘ä»¬ä¸å¦¨ä½¿ç”¨æ‰€æœ‰æ•°æ®å¯¹å…¶è¿›è¡Œè®­ç»ƒ
ï¼ˆè€Œä¸æ˜¯ä»…ä½¿ç”¨äº¤å‰éªŒè¯ä¸­ä½¿ç”¨çš„$1-1/K$çš„æ•°æ®ï¼‰ã€‚
ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡è¿™ç§æ–¹å¼è·å¾—çš„æ¨¡å‹å¯ä»¥åº”ç”¨äºæµ‹è¯•é›†ã€‚
å°†é¢„æµ‹ä¿å­˜åœ¨CSVæ–‡ä»¶ä¸­å¯ä»¥ç®€åŒ–å°†ç»“æœä¸Šä¼ åˆ°Kaggleçš„è¿‡ç¨‹ã€‚


```python
def train_and_pred(train_features, test_features, train_labels, test_data,
                   num_epochs, lr, weight_decay, batch_size):
    net = get_net()
    train_ls, _ = train(net, train_features, train_labels, None, None,
                        num_epochs, lr, weight_decay, batch_size)
    d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel='epoch',
             ylabel='log rmse', xlim=[1, num_epochs], yscale='log')
    print(f'è®­ç»ƒlog rmseï¼š{float(train_ls[-1]):f}')
    # å°†ç½‘ç»œåº”ç”¨äºæµ‹è¯•é›†ã€‚
    preds = net(test_features).detach().numpy()
    # å°†å…¶é‡æ–°æ ¼å¼åŒ–ä»¥å¯¼å‡ºåˆ°Kaggle
    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])
    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)
    submission.to_csv('submission.csv', index=False)

# å¦‚æœæµ‹è¯•é›†ä¸Šçš„é¢„æµ‹ä¸ğ¾ï¿½å€äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­çš„é¢„æµ‹ç›¸ä¼¼ï¼Œ é‚£å°±æ˜¯æ—¶å€™æŠŠå®ƒä»¬ä¸Šä¼ åˆ°Kaggleäº†ã€‚ ä¸‹é¢çš„ä»£ç å°†ç”Ÿæˆä¸€ä¸ªåä¸º`submission.csv`çš„æ–‡ä»¶ã€‚

train_and_pred(train_features, test_features, train_labels, test_data,
               num_epochs, lr, weight_decay, batch_size)
'''
è®­ç»ƒlog rmseï¼š0.162805
<Figure size 350x250 with 1 Axes>
'''
```

æ¥ä¸‹æ¥ï¼Œå¦‚ :numref:`fig_kaggle_submit2`ä¸­æ‰€ç¤ºï¼Œ æˆ‘ä»¬å¯ä»¥æäº¤é¢„æµ‹åˆ°Kaggleä¸Šï¼Œå¹¶æŸ¥çœ‹åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹ä¸å®é™…æˆ¿ä»·ï¼ˆæ ‡ç­¾ï¼‰çš„æ¯”è¾ƒæƒ…å†µã€‚ æ­¥éª¤éå¸¸ç®€å•ã€‚

- ç™»å½•Kaggleç½‘ç«™ï¼Œè®¿é—®æˆ¿ä»·é¢„æµ‹ç«èµ›é¡µé¢ã€‚
- ç‚¹å‡»â€œSubmit Predictionsâ€æˆ–â€œLate Submissionâ€æŒ‰é’®ï¼ˆåœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼Œè¯¥æŒ‰é’®ä½äºå³ä¾§ï¼‰ã€‚
- ç‚¹å‡»é¡µé¢åº•éƒ¨è™šçº¿æ¡†ä¸­çš„â€œUpload Submission Fileâ€æŒ‰é’®ï¼Œé€‰æ‹©è¦ä¸Šä¼ çš„é¢„æµ‹æ–‡ä»¶ã€‚
- ç‚¹å‡»é¡µé¢åº•éƒ¨çš„â€œMake Submissionâ€æŒ‰é’®ï¼Œå³å¯æŸ¥çœ‹ç»“æœã€‚

![[Pasted image 20240304135543.png|500]]:width:`400px`Â :label:`fig_kaggle_submit2`