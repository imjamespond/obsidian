
```python
import torch

x = torch.arange(12)
print(x,x.shape,x.numel())

X = x.reshape(3, 4)
print(X)

torch.zeros((2, 3, 4))
torch.ones((2, 3, 4))
torch.randn(3, 4)
torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
```
- \[**可以通过张量的`shape`属性来访问张量（沿每个轴的长度）的_形状_**] (~~和张量中元素的总数~~)。
- 如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。 因为这里在处理的是一个向量，所以它的`shape`与它的`size`相同。
- \[**要想改变一个张量的形状而不改变元素数量和元素值，可以调用`reshape`函数。**]
- 有时，我们希望\[**使用全0、全1、其他常量，或者从特定分布中随机采样的数字**]来初始化矩阵。 我们可以创建一个形状为（2,3,4）的张量，其中所有元素都设置为0。
- 同样，我们可以创建一个形状为`(2,3,4)`的张量，其中所有元素都设置为1。
- 有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。 例如，当我们构造数组来作为神经网络中的参数时，我们通常会随机初始化参数的值。 以下代码创建一个形状为（3,4）的张量。 其中的==每个元素都从均值为0、标准差为1的标准高斯分布==（正态分布）中随机采样
- 我们还可以\[**通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值**]。 在这里，最外层的列表对应于轴0，内层的列表对应于轴1。
```
tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]) torch.Size([12]) 12
tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
```

## 运算符
```python
x = torch.tensor([1.0, 2, 4, 8])
y = torch.tensor([2, 2, 2, 2])
x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算

torch.exp(x)

X = torch.arange(12, dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)
X == Y
X.sum()
```
-  在下面的例子中，我们使用逗号来表示一个具有5个元素的元组，其中每个元素都是按元素操作的结果。
- (**“按元素”方式可以应用更多的计算**)，包括像求幂这样的==一元运算符==。
- \[**我们也可以把多个张量_连结_（concatenate）在一起**]， 把它们端对端地叠起来形成一个更大的张量。 我们只需要提供张量列表，并给出沿哪个轴连结。 下面的例子分别演示了当我们==沿行（轴-0，形状的第一个元素）== 和==按列（轴-1，形状的第二个元素）连结两个矩阵时==，会发生什么情况。 我们可以看到，第一个输出张量的==轴-0长度（66）==是==两个输入张量轴-0长度的总和（3+33+3）==； 第二个输出张量的==轴-1长度（88）==是==两个输入张量轴-1长度的总和（4+44+4）==。
- 有时，我们想\[**通过_逻辑运算符_构建二元张量**]。 以`X == Y`为例： 对于每个位置，如果`X`和`Y`==在该位置相等==，则新张量中==相应项的值为1==。 这意味着逻辑语句`X == Y`在该位置处为真，否则该位置为0。
```
(tensor([ 3.,  4.,  6., 10.]),
 tensor([-1.,  0.,  2.,  6.]),
 tensor([ 2.,  4.,  8., 16.]),
 tensor([0.5000, 1.0000, 2.0000, 4.0000]),
 tensor([ 1.,  4., 16., 64.]))

tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])

(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         
         [ 2.,  1.,  4.,  3.],
         [ 1.,  2.,  3.,  4.],
         [ 4.,  3.,  2.,  1.]]),
tensor([[ 0.,  1.,  2.,  3.,      2.,  1.,  4.,  3.],
         [ 4.,  5.,  6.,  7.,      1.,  2.,  3.,  4.],
         [ 8.,  9., 10., 11.,      4.,  3.,  2.,  1.]]))
tensor([[False,  True, False,  True],
        [False, False, False, False],
        [False, False, False, False]])
tensor(66.)
```

## 广播机制
在上面的部分中，我们看到了如何在相同形状的两个张量上执行按元素操作。 在某些情况下，\[*_==即使形状不同==，我们仍然可以通过调用 _广播机制_（broadcasting mechanism）来执行按元素操作_*]。 这种机制的工作方式如下：
1. 通过适当复制元素来扩展一个或两个数组，以便在转换之后，==两个张量具有相同的形状==；
2. 对生成的数组执行按元素操作。
```python
a = torch.arange(3).reshape((3, 1))
b = torch.arange(2).reshape((1, 2))
a, b

a + b
```
- 由于`a`和`b`分别是$3\times1$和$1\times2$矩阵，如果让它们相加，它们的形状不匹配。我们将两个矩阵*广播*为一个更大的$3\times2$矩阵，如下所示：==矩阵`a`将复制**列**==，==矩阵`b`将复制**行**==，然后再按元素相加。

```
(tensor([[0],
         [1],
         [2]]),
tensor([[0, 1]]))

tensor([[0, 1],
        [1, 2],
        [2, 3]])
```

## 索引和切片

```python
X[-1], X[1:3]
X[1, 2] = 9
X[0:2, :] = 12
```
- 如下所示，我们\[**可以用`[-1]`选择最后一个元素，可以用`[1:3]`选择第二个和第三个元素**]：（4之前，不包括4）
    tensor(\[\[ 0.,  1.,  2.,  3.],
            \[ 4.,  5.,  6.,  7.],
            \[ 8.,  9., 10., 11.]]) 
- \[**除读取外，我们还可以通过指定索引来将元素写入矩阵。**]
- 如果我们想\[**为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值。**] 例如，`[0:2, :]`访问第1行和第2行，其中==“:”代表沿轴1（列）的所有元素==。 虽然我们讨论的是矩阵的索引，但这也适用于向量和超过2个维度的张量。(1,2行中的所有列)
```
(tensor([ 8.,  9., 10., 11.]),
 tensor([[ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.]]))

tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  9.,  7.],
        [ 8.,  9., 10., 11.]])

tensor([[12., 12., 12., 12.],
        [12., 12., 12., 12.],
        [ 8.,  9., 10., 11.]])

```